[
  {
    "paper_title": "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI",
    "papers": [
      {
        "title": "INTRODUCTION OF THE NATIONAL SYSTEM OF ACCOUNTING OF THE LENGTH OF HIGHWAYS IN SINGLE-LANE CALCULATION",
        "url": "https://www.semanticscholar.org/paper/ad30dae41ba44092fef89c21e8395c24ad0d2bd7",
        "abstract": "Introduction. The use of geographical spatial data of the public road network has led to the question of the feasibility of applying existing methods of road length accounting and the need to introduce single-lane road length accounting. Problem statement. The search for alternative ways to account for the length of a road calls for improving the principles of forming road titles, which have certain solutions for accounting for sections with more than one lane in each direction and establishing the lengths of traffic interchanges, additional lanes on ascents, external and internal transitional high-speed lanes, dedicated (channelized) lanes, etc. Objective. To improve the system of accounting for the length of public roads of national importance. Materials and methods. The principles of road titling introduced in [1] have certain solutions for accounting for sections with more than 1 lane in each direction and establishing the lengths of traffic interchanges, which were rational at the time of adoption, but without further improvement may be ineffective and increasingly lead to contradictions. The need to introduce the term \"length of a public road in single-lane calculation\" is due to the fact that there are fundamental differences between the lengths of roads approved by the Resolution of the Cabinet of Ministers of Ukraine \"On Approval of the List of Public Roads of National Importance\" of December 15, 2023 No. 1318 [2] and the actual length (area) of lanes subject to repair and maintenance, since the road may have a different number of main lanes along its length, additional lanes on ascents, external and internal transitional high-speed lanes, dedicated (channelized) lanes, and exits may have several lanes in one direction.",
        "source": "semantic_scholar",
        "score": 0.339,
        "matched_concept": "length"
      }
    ]
  },
  {
    "paper_title": "Explanation in Artificial Intelligence: Insights from the Social Sciences",
    "papers": [
      {
        "title": "HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge\n  in RAG Systems",
        "url": "http://arxiv.org/abs/2411.02959v2",
        "abstract": "Retrieval-Augmented Generation (RAG) has been shown to improve knowledge\ncapabilities and alleviate the hallucination problem of LLMs. The Web is a\nmajor source of external knowledge used in RAG systems, and many commercial RAG\nsystems have used Web search engines as their major retrieval systems.\nTypically, such RAG systems retrieve search results, download HTML sources of\nthe results, and then extract plain texts from the HTML sources. Plain text\ndocuments or chunks are fed into the LLMs to augment the generation. However,\nmuch of the structural and semantic information inherent in HTML, such as\nheadings and table structures, is lost during this plain-text-based RAG\nprocess. To alleviate this problem, we propose HtmlRAG, which uses HTML instead\nof plain text as the format of retrieved knowledge in RAG. We believe HTML is\nbetter than plain text in modeling knowledge in external documents, and most\nLLMs possess robust capacities to understand HTML. However, utilizing HTML\npresents new challenges. HTML contains additional content such as tags,\nJavaScript, and CSS specifications, which bring extra input tokens and noise to\nthe RAG system. To address this issue, we propose HTML cleaning, compression,\nand a two-step block-tree-based pruning strategy, to shorten the HTML while\nminimizing the loss of information. Experiments on six QA datasets confirm the\nsuperiority of using HTML in RAG systems.",
        "source": "arxiv",
        "score": 0.482,
        "matched_concept": "html"
      },
      {
        "title": "WAFFLE: Multi-Modal Model for Automated Front-End Development",
        "url": "http://arxiv.org/abs/2410.18362v1",
        "abstract": "Web development involves turning UI designs into functional webpages, which\ncan be difficult for both beginners and experienced developers due to the\ncomplexity of HTML's hierarchical structures and styles. While Large Language\nModels (LLMs) have shown promise in generating source code, two major\nchallenges persist in UI-to-HTML code generation: (1) effectively representing\nHTML's hierarchical structure for LLMs, and (2) bridging the gap between the\nvisual nature of UI designs and the text-based format of HTML code. To tackle\nthese challenges, we introduce Waffle, a new fine-tuning strategy that uses a\nstructure-aware attention mechanism to improve LLMs' understanding of HTML's\nstructure and a contrastive fine-tuning approach to align LLMs' understanding\nof UI images and HTML code. Models fine-tuned with Waffle show up to 9.00 pp\n(percentage point) higher HTML match, 0.0982 higher CW-SSIM, 32.99 higher CLIP,\nand 27.12 pp higher LLEM on our new benchmark WebSight-Test and an existing\nbenchmark Design2Code, outperforming current fine-tuning methods.",
        "source": "arxiv",
        "score": 0.495,
        "matched_concept": "html"
      },
      {
        "title": "Content Analysis: An Introduction to Its Methodology",
        "url": "https://www.semanticscholar.org/paper/25075e27b0df6f2be5a8c519171bdabd1c3ed817",
        "abstract": "History Conceptual Foundations Uses and Kinds of Inference The Logic of Content Analysis Designs Unitizing Sampling Recording Data Languages Constructs for Inference Analytical Techniques The Use of Computers Reliability Validity A Practical Guide",
        "source": "semantic_scholar",
        "score": 0.305,
        "matched_concept": "content"
      },
      {
        "title": "A Unified Framework for Generalizable Style Transfer: Style and Content\n  Separation",
        "url": "http://arxiv.org/abs/1806.05173v1",
        "abstract": "Image style transfer has drawn broad attention in recent years. However, most\nexisting methods aim to explicitly model the transformation between different\nstyles, and the learned model is thus not generalizable to new styles. We here\npropose a unified style transfer framework for both character typeface transfer\nand neural style transfer tasks leveraging style and content separation. A key\nmerit of such framework is its generalizability to new styles and contents. The\noverall framework consists of style encoder, content encoder, mixer and\ndecoder. The style encoder and content encoder are used to extract the style\nand content representations from the corresponding reference images. The mixer\nintegrates the above two representations and feeds it into the decoder to\ngenerate images with the target style and content. During training, the encoder\nnetworks learn to extract styles and contents from limited size of\nstyle/content reference images. This learning framework allows simultaneous\nstyle transfer among multiple styles and can be deemed as a special\n`multi-task' learning scenario. The encoders are expected to capture the\nunderlying features for different styles and contents which is generalizable to\nnew styles and contents. Under this framework, we design two individual\nnetworks for character typeface transfer and neural style transfer,\nrespectively. For character typeface transfer, to separate the style features\nand content features, we leverage the conditional dependence of styles and\ncontents given an image. For neural style transfer, we leverage the statistical\ninformation of feature maps in certain layers to represent style. Extensive\nexperimental results have demonstrated the effectiveness and robustness of the\nproposed methods.",
        "source": "arxiv",
        "score": 0.336,
        "matched_concept": "style"
      },
      {
        "title": "A Comprehensive Comparison between Neural Style Transfer and Universal\n  Style Transfer",
        "url": "http://arxiv.org/abs/1806.00868v1",
        "abstract": "Style transfer aims to transfer arbitrary visual styles to content images. We\nexplore algorithms adapted from two papers that try to solve the problem of\nstyle transfer while generalizing on unseen styles or compromised visual\nquality. Majority of the improvements made focus on optimizing the algorithm\nfor real-time style transfer while adapting to new styles with considerably\nless resources and constraints. We compare these strategies and compare how\nthey measure up to produce visually appealing images. We explore two approaches\nto style transfer: neural style transfer with improvements and universal style\ntransfer. We also make a comparison between the different images produced and\nhow they can be qualitatively measured.",
        "source": "arxiv",
        "score": 0.416,
        "matched_concept": "style"
      },
      {
        "title": "Computational Decomposition of Style for Controllable and Enhanced Style\n  Transfer",
        "url": "http://arxiv.org/abs/1811.08668v2",
        "abstract": "Neural style transfer has been demonstrated to be powerful in creating\nartistic image with help of Convolutional Neural Networks (CNN). However, there\nis still lack of computational analysis of perceptual components of the\nartistic style. Different from some early attempts which studied the style by\nsome pre-processing or post-processing techniques, we investigate the\ncharacteristics of the style systematically based on feature map produced by\nCNN. First, we computationally decompose the style into basic elements using\nnot only spectrum based methods including Fast Fourier Transform (FFT),\nDiscrete Cosine Transform (DCT) but also latent variable models such Principal\nComponent Analysis (PCA), Independent Component Analysis (ICA). Then, the\ndecomposition of style induces various ways of controlling the style elements\nwhich could be embedded as modules in state-of-the-art style transfer\nalgorithms. Such decomposition of style brings several advantages. It enables\nthe computational coding of different artistic styles by our style basis with\nsimilar styles clustering together, and thus it facilitates the mixing or\nintervention of styles based on the style basis from more than one styles so\nthat compound style or new style could be generated to produce styled images.\nExperiments demonstrate the effectiveness of our method on not only painting\nstyle transfer but also sketch style transfer which indicates possible\napplications on picture-to-sketch problems.",
        "source": "arxiv",
        "score": 0.384,
        "matched_concept": "style"
      },
      {
        "title": "Style Decomposition for Improved Neural Style Transfer",
        "url": "http://arxiv.org/abs/1811.12704v1",
        "abstract": "Universal Neural Style Transfer (NST) methods are capable of performing style\ntransfer of arbitrary styles in a style-agnostic manner via feature transforms\nin (almost) real-time. Even though their unimodal parametric style modeling\napproach has been proven adequate to transfer a single style from relatively\nsimple images, they are usually not capable of effectively handling more\ncomplex styles, producing significant artifacts, as well as reducing the\nquality of the synthesized textures in the stylized image. To overcome these\nlimitations, in this paper we propose a novel universal NST approach that\nseparately models each sub-style that exists in a given style image (or a\ncollection of style images). This allows for better modeling the subtle style\ndifferences within the same style image and then using the most appropriate\nsub-style (or mixtures of different sub-styles) to stylize the content image.\nThe ability of the proposed approach to a) perform a wide range of different\nstylizations using the sub-styles that exist in one style image, while giving\nthe ability to the user to appropriate mix the different sub-styles, b)\nautomatically match the most appropriate sub-style to different semantic\nregions of the content image, improving existing state-of-the-art universal NST\napproaches, and c) detecting and transferring the sub-styles from collections\nof images are demonstrated through extensive experiments.",
        "source": "arxiv",
        "score": 0.415,
        "matched_concept": "style"
      },
      {
        "title": "Introduction to Text Visualization",
        "url": "https://www.semanticscholar.org/paper/31b2b83eeb31d5138933b130d50c62239d5c784d",
        "abstract": "This book provides a systematic review of many advanced techniques to support the analysis of large collections of documents, ranging from the elementary to the profound, covering all the aspects of the visualization of text documents. Particularly, we start by introducing the fundamental concept of information visualization and visual analysis, followed by a brief survey of the field of text visualization and commonly used data models for converting document into a structured form for visualization. Then we introduce the key visualization techniques including visualizing document similarity, content, sentiments, as well as text corpus exploration system in details with concrete examples in the rest of the book.",
        "source": "semantic_scholar",
        "score": 0.397,
        "matched_concept": "text"
      }
    ]
  },
  {
    "paper_title": "Impact of Artificial Intelligence in Customer Journey",
    "papers": [
      {
        "title": "On the Impact of DNS Over HTTPS Paradigm on Cyber Systems",
        "url": "https://www.semanticscholar.org/paper/731fbccb858cb17c7b73bde0a0ed71b7694b7e96",
        "abstract": "The Domain Name System (DNS) protocol has been in use for over thirty years. As the primary method of resolving domain names to Internet Protocol (IP) addresses, it is a fundamental component of the Internet. Despite its position of importance, the protocol lacks built-in security mechanisms to address confidentiality, integrity, or availability. Malware can use DNS to fulfill attacker objectives, such as establishing command and control (C2) or exfiltrating data. Various enhancements have been implemented in an attempt to address security after-the-fact. The latest such enhancement is DNS over HTTPS. Methods have also been developed to detect malware's use of DNS. In this paper, we review the weaknesses of the DNS protocol and how malware has abused those weaknesses, enhancements to DNS security, and how malware uses DNS and how that use is detected, with a special emphasis on the effects that DNS over HTTPS may have on an organization's security.",
        "source": "semantic_scholar",
        "score": 0.441,
        "matched_concept": "https"
      },
      {
        "title": "MCTformer+: Multi-Class Token Transformer for Weakly Supervised Semantic\n  Segmentation",
        "url": "http://arxiv.org/abs/2308.03005v1",
        "abstract": "This paper proposes a novel transformer-based framework that aims to enhance\nweakly supervised semantic segmentation (WSSS) by generating accurate\nclass-specific object localization maps as pseudo labels. Building upon the\nobservation that the attended regions of the one-class token in the standard\nvision transformer can contribute to a class-agnostic localization map, we\nexplore the potential of the transformer model to capture class-specific\nattention for class-discriminative object localization by learning multiple\nclass tokens. We introduce a Multi-Class Token transformer, which incorporates\nmultiple class tokens to enable class-aware interactions with the patch tokens.\nTo achieve this, we devise a class-aware training strategy that establishes a\none-to-one correspondence between the output class tokens and the ground-truth\nclass labels. Moreover, a Contrastive-Class-Token (CCT) module is proposed to\nenhance the learning of discriminative class tokens, enabling the model to\nbetter capture the unique characteristics and properties of each class. As a\nresult, class-discriminative object localization maps can be effectively\ngenerated by leveraging the class-to-patch attentions associated with different\nclass tokens. To further refine these localization maps, we propose the\nutilization of patch-level pairwise affinity derived from the patch-to-patch\ntransformer attention. Furthermore, the proposed framework seamlessly\ncomplements the Class Activation Mapping (CAM) method, resulting in\nsignificantly improved WSSS performance on the PASCAL VOC 2012 and MS COCO 2014\ndatasets. These results underline the importance of the class token for WSSS.",
        "source": "arxiv",
        "score": 0.319,
        "matched_concept": "class"
      }
    ]
  }
]